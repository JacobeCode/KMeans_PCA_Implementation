Extra Trees Algorithm
[Supervised; Predictive modeling; Classification and Regression]
{Versitaile; Easy interpretable; Good visualization}
{Risk of overfit; Sensitivity; Bias on imbalanced data}

Each node is a decision (test on atribute)
Each branch is an attribute value
Each leaf is a result of prediction

Main terminology connected to tree-like structure -
most important and unusual one is pruning.

Pruning - removing branches or nodes from a tree to prevent overfitting

Splitting till criterion is met (depth or minimum number of instances)
Splitting data based on best criterium (information gain or Gini)

Information gain - information gained about random variable by observation conducted on another variable (measure of change in entropy)
Gini impurity - measure of how frequently a random chosen element of set would be incorrectly labeled if it were labeled randomly and independently of data distribution - zero at falling all cases in node to single category
[It is calculated by summing the squared probabilities of each outcome in a distribution and subtracting the result from 1.]

Entropy: is the measure of uncertainty of a random variable, it characterizes the impurity of an arbitrary collection of examples. The higher the entropy more the information content.